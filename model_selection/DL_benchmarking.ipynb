{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master Benchmarking for Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # Nvidia Quadro GV100\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" # Nvidia Quadro M2000\n",
    "\n",
    "#Adding Path to various Modules\n",
    "sys.path.append(\"../core\")\n",
    "sys.path.append(\"../visualization\")\n",
    "sys.path.append(\"../utilities\")\n",
    "sys.path.append(\"../datasets\")\n",
    "sys.path.append(\"../trained_models\")\n",
    "sys.path.append(\"../config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing Required Modules\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "#Importing Config files\n",
    "import assembly_config as config\n",
    "import model_config as cftrain\n",
    "import hybrid_utils as hy_util\n",
    "#Importing required modules from the package\n",
    "from measurement_system import HexagonWlsScanner\n",
    "from assembly_system import VRMSimulationModel\n",
    "from wls400a_system import GetInferenceData\n",
    "from data_import import GetTrainData\n",
    "from encode_decode_model import Encode_Decode_Model\n",
    "from training_viz import TrainViz\n",
    "from metrics_eval import MetricsEval\n",
    "from keras_lr_multiplier import LRMultiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing from Assembly Config File....\n"
     ]
    }
   ],
   "source": [
    "print('Parsing from Assembly Config File....')\n",
    "\n",
    "data_type=config.assembly_system['data_type']\n",
    "application=config.assembly_system['application']\n",
    "part_type=config.assembly_system['part_type']\n",
    "part_name=config.assembly_system['part_name']\n",
    "data_format=config.assembly_system['data_format']\n",
    "assembly_type=config.assembly_system['assembly_type']\n",
    "assembly_kccs=config.assembly_system['assembly_kccs']\n",
    "assembly_kpis=config.assembly_system['assembly_kpis']\n",
    "voxel_dim=config.assembly_system['voxel_dim']\n",
    "point_dim=config.assembly_system['point_dim']\n",
    "voxel_channels=config.assembly_system['voxel_channels']\n",
    "noise_type=config.assembly_system['noise_type']\n",
    "mapping_index=config.assembly_system['mapping_index']\n",
    "\n",
    "system_noise=config.assembly_system['system_noise']\n",
    "aritifical_noise=config.assembly_system['aritifical_noise']\n",
    "data_folder=config.assembly_system['data_folder']\n",
    "kcc_folder=config.assembly_system['kcc_folder']\n",
    "kcc_files=config.assembly_system['kcc_files']\n",
    "test_kcc_files=config.assembly_system['test_kcc_files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing from Training Config File\n"
     ]
    }
   ],
   "source": [
    "#added for hybrid model\n",
    "categorical_kccs=config.assembly_system['categorical_kccs']\n",
    "\n",
    "print('Parsing from Training Config File')\n",
    "\n",
    "model_type=cftrain.model_parameters['model_type']\n",
    "output_type=cftrain.model_parameters['output_type']\n",
    "batch_size=cftrain.model_parameters['batch_size']\n",
    "epocs=cftrain.model_parameters['epocs']\n",
    "split_ratio=cftrain.model_parameters['split_ratio']\n",
    "optimizer=cftrain.model_parameters['optimizer']\n",
    "loss_func=cftrain.model_parameters['loss_func']\n",
    "regularizer_coeff=cftrain.model_parameters['regularizer_coeff']\n",
    "activate_tensorboard=cftrain.model_parameters['activate_tensorboard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file Structure....\n"
     ]
    }
   ],
   "source": [
    "print('Creating file Structure....')\n",
    "\n",
    "bn_model_name='fcnn_bn'\n",
    "\n",
    "folder_name=part_type\n",
    "train_path='../trained_models/'+part_type\n",
    "pathlib.Path(train_path).mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "train_path=train_path+'/'+bn_model_name\n",
    "pathlib.Path(train_path).mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "model_path=train_path+'/models'\n",
    "pathlib.Path(model_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logs_path=train_path+'/logs'\n",
    "pathlib.Path(logs_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "plots_path=train_path+'/plots'\n",
    "pathlib.Path(plots_path).mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the Assembly System and Measurement System....\n",
      "Valid Output Stages and heads\n",
      "KCC sub-listing:  0\n",
      "Process Parameter Dimension:  157\n"
     ]
    }
   ],
   "source": [
    "#Objects of Measurement System, Assembly System, Get Inference Data\n",
    "print('Initializing the Assembly System and Measurement System....')\n",
    "measurement_system=HexagonWlsScanner(data_type,application,system_noise,part_type,data_format)\n",
    "vrm_system=VRMSimulationModel(assembly_type,assembly_kccs,assembly_kpis,part_name,part_type,voxel_dim,voxel_channels,point_dim,aritifical_noise)\n",
    "get_data=GetTrainData()\n",
    "\n",
    "\n",
    "kcc_sublist=cftrain.encode_decode_params['kcc_sublist']\n",
    "output_heads=cftrain.encode_decode_params['output_heads']\n",
    "encode_decode_multi_output_construct=config.encode_decode_multi_output_construct\n",
    "\n",
    "if(output_heads==len(encode_decode_multi_output_construct)):\n",
    "\tprint(\"Valid Output Stages and heads\")\n",
    "else:\n",
    "\tprint(\"Inconsistent model setting\")\n",
    "\n",
    "print(\"KCC sub-listing: \",kcc_sublist)\n",
    "\n",
    "#Check for KCC sub-listing\n",
    "if(kcc_sublist!=0):\n",
    "\toutput_dimension=len(kcc_sublist)\n",
    "else:\n",
    "\toutput_dimension=assembly_kccs\n",
    "\n",
    "print(\"Process Parameter Dimension: \",output_dimension)\n",
    "\n",
    "input_size=(voxel_dim,voxel_dim,voxel_dim,voxel_channels)\n",
    "\n",
    "model_depth=cftrain.encode_decode_params['model_depth']\n",
    "inital_filter_dim=cftrain.encode_decode_params['inital_filter_dim']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all Process Parameter\n"
     ]
    }
   ],
   "source": [
    "#importing file names for model input\n",
    "input_file_names_x=config.encode_decode_construct['input_data_files_x']\n",
    "input_file_names_y=config.encode_decode_construct['input_data_files_y']\n",
    "input_file_names_z=config.encode_decode_construct['input_data_files_z']\n",
    "\n",
    "input_dataset=[]\n",
    "input_dataset.append(get_data.data_import(input_file_names_x,data_folder))\n",
    "input_dataset.append(get_data.data_import(input_file_names_y,data_folder))\n",
    "input_dataset.append(get_data.data_import(input_file_names_z,data_folder))\n",
    "\n",
    "kcc_dataset=get_data.data_import(kcc_files,kcc_folder)\n",
    "\n",
    "if(kcc_sublist!=0):\n",
    "\tprint(\"Sub-setting Process Parameters: \",kcc_sublist)\n",
    "\tkcc_dataset=kcc_dataset.iloc[:,kcc_sublist]\n",
    "\ttest_kcc_dataset=test_kcc_dataset[:,kcc_sublist]\n",
    "else:\n",
    "\tprint(\"Using all Process Parameter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:42<00:00, 11.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of not convergent solutions:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Pre-processing to point cloud data\n",
    "point_index=get_data.load_mapping_index(mapping_index)\n",
    "input_conv_data, kcc_subset_dump,kpi_subset_dump=get_data.data_convert_voxel_mc(vrm_system,input_dataset,point_index,kcc_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing output data for stage:  {'stage_id': 2, 'output_data_files_x': ['DX_crossmember_test1_3.csv'], 'output_data_files_y': ['DY_crossmember_test1_3.csv'], 'output_data_files_z': ['DZ_crossmember_test1_3.csv'], 'output_test_data_files_x': ['DX_crossmember_test1_3.csv'], 'output_test_data_files_y': ['DY_crossmember_test1_3.csv'], 'output_test_data_files_z': ['DZ_crossmember_test1_3.csv']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:42<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of not convergent solutions:  0\n",
      "Importing output data for stage:  {'stage_id': 6, 'output_data_files_x': ['DX_crossmember_test1_7.csv'], 'output_data_files_y': ['DY_crossmember_test1_7.csv'], 'output_data_files_z': ['DZ_crossmember_test1_7.csv'], 'output_test_data_files_x': ['DX_crossmember_test1_7.csv'], 'output_test_data_files_y': ['DY_crossmember_test1_7.csv'], 'output_test_data_files_z': ['DZ_crossmember_test1_7.csv']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:42<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of not convergent solutions:  0\n"
     ]
    }
   ],
   "source": [
    "y_shape_error_list=[]\n",
    "\n",
    "for encode_decode_construct in encode_decode_multi_output_construct:\n",
    "\t#importing file names for model output\n",
    "\tprint(\"Importing output data for stage: \",encode_decode_construct)\n",
    "\n",
    "\toutput_file_names_x=encode_decode_construct['output_data_files_x']\n",
    "\toutput_file_names_y=encode_decode_construct['output_data_files_y']\n",
    "\toutput_file_names_z=encode_decode_construct['output_data_files_z']\n",
    "\n",
    "\toutput_dataset=[]\n",
    "\toutput_dataset.append(get_data.data_import(output_file_names_x,data_folder))\n",
    "\toutput_dataset.append(get_data.data_import(output_file_names_y,data_folder))\n",
    "\toutput_dataset.append(get_data.data_import(output_file_names_z,data_folder))\n",
    "\n",
    "\toutput_conv_data, kcc_subset_dump,kpi_subset_dump=get_data.data_convert_voxel_mc(vrm_system,output_dataset,point_index,kcc_dataset)\n",
    "\n",
    "\ty_shape_error_list.append(output_conv_data)\n",
    "\n",
    "shape_error=np.concatenate(y_shape_error_list, axis=4)\n",
    "kcc_regression,kcc_classification=hy_util.split_kcc(kcc_subset_dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Benchmarking Input Output\n",
    "# 1 Only Regression\n",
    "# 2 Only Classfication\n",
    "# 3 Only Shape Error\n",
    "# 4 Regression + Classification\n",
    "# 5 Regression + OSE\n",
    "# 6 Regression + Classification\n",
    "# 7 Regression + Classification + OSE\n",
    "#Select Option to execute\n",
    "option_num=3\n",
    "\n",
    "from bm_selector import get_bm_io\n",
    "\n",
    "y_out_list=get_bm_io(option_num,kcc_regression,kcc_classification,shape_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model using Keras Tuner\n",
    "\n",
    "#Get Base Model\n",
    "#Reloading to change cache\n",
    "import importlib\n",
    "import dl_models\n",
    "importlib.reload(dl_models)\n",
    "\n",
    "dl_model_obj2=dl_models.DL_BM_Arch(output_dimension)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D FCNN model successfully compiled\n",
      "Model: \"FCNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 64, 64, 64, 3)]   0         \n",
      "_________________________________________________________________\n",
      "Conv0_1 (Conv3D)             (None, 64, 64, 64, 32)    2624      \n",
      "_________________________________________________________________\n",
      "Act0_1 (Activation)          (None, 64, 64, 64, 32)    0         \n",
      "_________________________________________________________________\n",
      "MaxPooling0_1 (MaxPooling3D) (None, 32, 32, 32, 32)    0         \n",
      "_________________________________________________________________\n",
      "Conv1_1 (Conv3D)             (None, 32, 32, 32, 64)    55360     \n",
      "_________________________________________________________________\n",
      "Act1_1 (Activation)          (None, 32, 32, 32, 64)    0         \n",
      "_________________________________________________________________\n",
      "MaxPooling1_1 (MaxPooling3D) (None, 16, 16, 16, 64)    0         \n",
      "_________________________________________________________________\n",
      "Conv2_1 (Conv3D)             (None, 16, 16, 16, 128)   221312    \n",
      "_________________________________________________________________\n",
      "Act2_1 (Activation)          (None, 16, 16, 16, 128)   0         \n",
      "_________________________________________________________________\n",
      "MaxPooling2_1 (MaxPooling3D) (None, 8, 8, 8, 128)      0         \n",
      "_________________________________________________________________\n",
      "UpSampling2_1 (UpSampling3D) (None, 16, 16, 16, 128)   0         \n",
      "_________________________________________________________________\n",
      "upConvSam2_1 (Conv3D)        (None, 16, 16, 16, 128)   131200    \n",
      "_________________________________________________________________\n",
      "upConv2_1 (Conv3D)           (None, 16, 16, 16, 128)   442496    \n",
      "_________________________________________________________________\n",
      "upAct2_1 (Activation)        (None, 16, 16, 16, 128)   0         \n",
      "_________________________________________________________________\n",
      "upAct2_2 (Activation)        (None, 16, 16, 16, 128)   0         \n",
      "_________________________________________________________________\n",
      "UpSampling1_1 (UpSampling3D) (None, 32, 32, 32, 128)   0         \n",
      "_________________________________________________________________\n",
      "upConvSam1_1 (Conv3D)        (None, 32, 32, 32, 64)    65600     \n",
      "_________________________________________________________________\n",
      "upConv1_1 (Conv3D)           (None, 32, 32, 32, 64)    110656    \n",
      "_________________________________________________________________\n",
      "upAct1_1 (Activation)        (None, 32, 32, 32, 64)    0         \n",
      "_________________________________________________________________\n",
      "upAct1_2 (Activation)        (None, 32, 32, 32, 64)    0         \n",
      "_________________________________________________________________\n",
      "UpSampling0_1 (UpSampling3D) (None, 64, 64, 64, 64)    0         \n",
      "_________________________________________________________________\n",
      "upConvSam0_1 (Conv3D)        (None, 64, 64, 64, 32)    16416     \n",
      "_________________________________________________________________\n",
      "upConv0_1 (Conv3D)           (None, 64, 64, 64, 32)    27680     \n",
      "_________________________________________________________________\n",
      "upAct0_1 (Activation)        (None, 64, 64, 64, 32)    0         \n",
      "_________________________________________________________________\n",
      "upAct0_2 (Activation)        (None, 64, 64, 64, 32)    0         \n",
      "_________________________________________________________________\n",
      "shape_error_outputs (Conv3D) (None, 64, 64, 64, 6)     198       \n",
      "=================================================================\n",
      "Total params: 1,073,542\n",
      "Trainable params: 1,073,542\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Import Benchmarking Model\n",
    "model=dl_model_obj2.fcnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 350 samples, validate on 150 samples\n",
      "Epoch 1/3\n",
      "336/350 [===========================>..] - ETA: 1s - loss: 0.0050 - mean_absolute_error: 0.0070\n",
      "Epoch 00001: val_loss improved from inf to 0.00469, saving model to ../trained_models/cross_member_assembly/fcnn_bn\n",
      "350/350 [==============================] - 36s 104ms/sample - loss: 0.0050 - mean_absolute_error: 0.0070 - val_loss: 0.0047 - val_mean_absolute_error: 0.0058\n",
      "Epoch 2/3\n",
      "336/350 [===========================>..] - ETA: 0s - loss: 0.0050 - mean_absolute_error: 0.0075\n",
      "Epoch 00002: val_loss improved from 0.00469 to 0.00463, saving model to ../trained_models/cross_member_assembly/fcnn_bn\n",
      "350/350 [==============================] - 21s 61ms/sample - loss: 0.0050 - mean_absolute_error: 0.0075 - val_loss: 0.0046 - val_mean_absolute_error: 0.0090\n",
      "Epoch 3/3\n",
      "336/350 [===========================>..] - ETA: 0s - loss: 0.0047 - mean_absolute_error: 0.0078\n",
      "Epoch 00003: val_loss improved from 0.00463 to 0.00437, saving model to ../trained_models/cross_member_assembly/fcnn_bn\n",
      "350/350 [==============================] - 22s 62ms/sample - loss: 0.0048 - mean_absolute_error: 0.0078 - val_loss: 0.0044 - val_mean_absolute_error: 0.0068\n"
     ]
    }
   ],
   "source": [
    "##Train Benchmarking Model\n",
    "from tensorflow.keras import backend as K\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(train_path, verbose=1, save_best_only='val_loss',save_weights_only=True)\n",
    "history=model.fit(x=input_conv_data,y=y_out_list, validation_split=0.3, epochs=epocs, batch_size=batch_size,callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Test Dataset\n",
    "# Get Test Metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
